{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25386a9-1b8a-444f-b131-009007ccde9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae1cf24-b4ef-49e2-96be-d80db7699927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file ./TTbar_set1.h5\n",
      "finish reading files\n"
     ]
    }
   ],
   "source": [
    "Xorg, Y = read_input('inputs.txt')\n",
    "\n",
    "\n",
    "# inputs.txt contains one dataset\n",
    "# X is training data; Y is validation??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549539e4-31dd-4867-9294-dbd15f45668e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 13, 1: 3}\n"
     ]
    }
   ],
   "source": [
    "Y = Y / -1\n",
    "\n",
    "Xi, Xc1, Xc2 = preProcessing(Xorg, 1)\n",
    "Xc = [Xc1, Xc2]\n",
    "\n",
    "emb_input_dim = {i:int(np.max(Xc[i][0:1000])) + 1 for i in range(2) }\n",
    "print(emb_input_dim)\n",
    "\n",
    "# Prepare training/val data\n",
    "Yr = Y\n",
    "Xr = [Xi] + Xc\n",
    "\n",
    "# This is copied from train.py\n",
    "# Question: do we know the dimensoins genercially (before reading the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c4e62a-9892-4bc9-83af-17f1f09ac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inputs.txt') as f:\n",
    "    sets = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a597d0-f072-4a24-b487-f9cc14ad4019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./TTbar_set1.h5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28626dd9-1666-4a3c-be67-54a5c5ebd65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition= {}\n",
    "partition['train'] = [f'{sets[0]}']\n",
    "partition['validation'] = [f'{sets[0]}']\n",
    "i = 0\n",
    "for set in sets:\n",
    "    if i != 0:\n",
    "        partition['train'] += [f'{set}']\n",
    "        partition['validation'] += [f'id-{set}']\n",
    "    i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cee9438-66e4-4c70-bdcd-4b7f3acbd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "labels[f'{sets[0]}'] = [0]\n",
    "i = 0\n",
    "for set in sets:\n",
    "    if i != 0:\n",
    "        labels[f'set'] = i\n",
    "\n",
    "# sets up partitions and labels per the example\n",
    "# Question: is the goal of this data generator to give the model one file at a time or a subset (batch size) of a file at one time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f233a76-f850-48cf-8b26-960371d4f407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=1024, dim=(1,100,8), n_channels=1,\n",
    "                 n_classes=10, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def read_file(self, fname):\n",
    "        #print(\"read file\", fname)\n",
    "        h5f = h5py.File( fname, 'r')\n",
    "        X = h5f['X'][:]\n",
    "        Y = h5f['Y'][:]\n",
    "        #print(\"finish reading files\")\n",
    "        A = X[:, :, :]\n",
    "        B = Y[:, :]\n",
    "        return A, B\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = self.read_file(ID)\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "    \n",
    "# copied from the example; added a method to read any given h5 file\n",
    "# I think something is wrong with dimenions ive set, but i'm lacking an intuision (see error in line 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71c73d97-9ebf-4af8-afd6-e8b9df4d881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (1,100,8),\n",
    "          'batch_size': 1024,\n",
    "          'n_classes': 6,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "094d5f00-1e52-47ce-b9ce-ea6bbbe113b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ded2983-a2a0-480f-b3c6-4f37eaa444b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file ./TTbar_set1.h5\n",
      "finish reading files\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (161837,100,8) into shape (161837)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-baae54b4f32a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-339c0b20093f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-339c0b20093f>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# Store sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Store class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (161837,100,8) into shape (161837)"
     ]
    }
   ],
   "source": [
    "training_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f3ef2-5f66-4306-bea5-e284bbe42273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
